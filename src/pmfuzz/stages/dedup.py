""" 
@file       dedup.py
@details    TODO
@copyright  2020-21 University of Virginia

SPDX-license-identifier: BSD-3-Clause
"""
import pickledb
import re
import sys
import time

from os import path
from os import makedirs
from os import listdir
from os import remove
from shutil import which
from shutil import rmtree

import handlers.name_handler as nh

from core.dedupengine import DedupEngine
from helper.common import *
from helper import config
from helper import parallel
from interfaces.afl import gen_tgt_img
from interfaces.afl import run_afl_tmin
from interfaces.afl import run_afl_cmin
from helper.ptimer import PTimer
from helper.prettyprint import *
from stages.stage import Stage

class Dedup(Stage):
    """ @brief Run deduplication of all three fuzzing dimensions for specified 
    stage and iter_id. 
    
    ### Working details
    #### afl-cmin scripts
    PMFuzz uses a modified afl-cmin that allows running minimization on a 
    corpus with diverse target command. e.g., 1.testcase is executed using CMD_A
    while 2.testcase using CMD_B. The modified afl-cmin allows this using a new
    option '-c' that points to a directory containing shell scripts called 
    `{1|2}.testcase.{before|after}`.
    
    `*.before`: Echos the command to run, in case of 1.testcase.before it would
    be CMD_A. e.g., `echo $CMD_A`
    
    `*.after`: Used for cleanup (if any)

    @TODO Update with new design that uses map files generated by AFL
    """

    # Result directory name for stage 1 directory
    MAP_DIR             = 'maps'        # Holds the maps (trace_bits and trace_pm_bits)
    TESTCASE_DIR        = 'testcases'   # Holds the testcases
    PM_IMG_DIR          = 'pm_images'   # Holds the images generated from testcases
    DEDUP_DIR_GBL       = '@dedup'      
    DEDUP_DIR_LOC       = '@dedup_sync'
    OUTPUT_TC_DIR       = path.join(nh.AFL_DIR_NM, 'master_fuzzer/queue')

    EXT_MIN_TC          = '.min.testcase'
    EXT_TC              = '.testcase'
    EXT_PM_POOL         = '.pm_pool'
    EXT_PM_CMPR_POOL    = '.pm_pool.tar.gz'


    def __init__(self, stage, iter_id, srcdir, outdir, cfg, cores, verbose, 
            force_resp, dry_run):
        super().__init__('', srcdir, outdir, cfg, cores, verbose, 
                            force_resp, dry_run)
    
        self.stage          = stage
        self.iter_id        = iter_id

        self.resultdir      = path.join(self.outdir, \
                                nh.get_outdir_name(stage, iter_id))
        self.total_min_dir  = path.join(self.resultdir, nh.ST2_MIN_DIR)
        self.tc_dir         = path.join(self.resultdir, Dedup.TESTCASE_DIR)
        self.img_dir        = path.join(self.resultdir, Dedup.PM_IMG_DIR)
        self.dedup_dir_gbl  = path.join(self.outdir, Dedup.DEDUP_DIR_GBL)
        self.dedup_dir_loc  = path.join(self.resultdir, Dedup.DEDUP_DIR_LOC)
        self.o_tc_dir       = path.join(self.resultdir, Dedup.OUTPUT_TC_DIR)

        # Create all the directories at startup
        self._gen_dirs()
        
        self.crash_site_db_f = path.join(self.outdir, '@crashsitehashes.db')
        
        if verbose:
            printv('Creating dedup for stage %d with iter_id %d' % (stage, iter_id))

    def _gen_dirs(self):
        """ Generates all the required directories """

        try:
            makedirs(self.dedup_dir_gbl)
        except OSError as e:
            if path.isfile(self.dedup_dir_gbl):
                abort('%s is not a directory.' % self.dedup_dir_gbl)

        try:
            makedirs(self.dedup_dir_loc)
        except OSError as e:
            if path.isfile(self.dedup_dir_loc):
                abort('%s is not a directory.' % self.dedup_dir_loc)
        try: 
            makedirs(self.tc_dir)
        except OSError as e:
            if path.isfile(self.tc_dir):
                abort('%s is not a directory.' % self.tc_dir)

        self.tempdir = path.join(self.outdir, '@temp')
        try: 
            makedirs(self.tempdir)
        except OSError as e:
            if path.isfile(self.tempdir):
                abort('%s is not a directory.' % self.tempdir)
        
        try:
            makedirs(self.img_dir)
        except OSError as e:
            if path.isfile(self.img_dir):
                abort('%s is not a directory.' % self.img_dir)

    def should_use_cs(self, tc_p: str):
        """ Returns True if the give tc_p would be ever used """
        result = False 

        ids = set()
        if 'select_ids' in self.cfg['pmfuzz']['stage']['2']:
            ids = set(self.cfg['pmfuzz']['stage']['2']['select_ids'])
        # elif self.verbose:
        #     printv('Skipping stage 2 select ids, none found')

        if len(ids) == 0:
            result = True
        else:
            lineage = set(
                nh.get_lineage(
                    tc_p.replace(nh.CMPR_PM_IMG_EXT, nh.TC_EXT)
                )
            )
            result = lineage - ids # Elements in ids and not in lineage
            if len(result) > 0:
                result = False
            else:
                result = True
        return result

    def should_use_tc(self, tc_p: str):
        """ Returns True if the give tc_p would be ever used """

        result = False 
        
        ids = set()
        if 'select_ids' in self.cfg['pmfuzz']['stage']['2']:
            ids = set(self.cfg['pmfuzz']['stage']['2']['select_ids'])
        elif self.verbose:
            printv('Skipping stage 2 select ids, none found')
        
        if len(ids) == 0:
            result = True
        else:
            lineage = set(nh.get_lineage(tc_p))
            result = lineage - ids # Elements in ids and not in lineage
            if len(result) > 0:
                result = False
            else:
                result = True
        return result

    def minimize_testcase(self, testcase):
        """ Minimizes a single testcse, current uses afl-tmin """
        # TODO: use the orignal target command image location

        testcasename = path.basename(testcase)
        _, gbl_img = map(list, zip(*self.global_dedup_list_tc))

        if self.verbose:
            printv('Minimizing ' + testcasename)

        parent_tc_name = nh.get_testcase_parent(testcasename)
        parent_img_name = parent_tc_name.replace(Dedup.EXT_TC, Dedup.EXT_PM_POOL)

        tgtcmd_loc = list(self.cfg.tgtcmd)

        img_path = ''
        
        # Set the image path to the parent image if this testcase was generated
        # on top of an existing image
        if parent_img_name in gbl_img:
            img_path = path.join(self.dedup_dir_gbl, parent_img_name)
        else:
            img_path = tempfile.mktemp(prefix='pmfuzz-temp-img-', 
                            dir=nh.get_img_dir(tgtcmd_loc))
            
            # Generate the image since it does not exist
            _, tgtcmd_img_gen = nh.set_img_path(tgtcmd_loc, img_path, self.cfg)
            gen_tgt_img(tgtcmd_img_gen, self.cfg, verbose=self.verbose) 

        # Generate the target command with new image path
        _, tgtcmd_loc = nh.set_img_path(tgtcmd_loc, img_path, self.cfg)

        run_afl_tmin(
            in_tc       = testcase, 
            out_tc      = nh.get_tc_min(testcase, Dedup.EXT_TC),
            tgtcmd      = tgtcmd_loc,
            cfg         = self.cfg, 
            persist_tgt = False,
            verbose     = self.verbose,
            dry_run     = self.dry_run,
        )

        if self.verbose:
            printw('Deleting: ' + img_path)

        remove(img_path)

    def minimize_testcases(self):
        """ Minimize global testcases 
        
        @return None"""
        
        abort_if(len(self.global_dedup_list_tc) == 0, 
            'Empty global deduplication list')

        testcases, _ = map(list, zip(*self.global_dedup_list_tc))

        prl = parallel.Parallel(self.minimize_testcase, self.cores)
        
        for testcase in testcases:
            
            # Only process unminimized testcases, exclude anything that has 
            # .min in its name
            if nh.is_tc(testcase):
                # TODO: fix this
                # Get the minimized name to check if this is already processed
                testcase_min_name = nh.get_tc_min(testcase, Dedup.EXT_TC)

                if not testcase_min_name in testcases:
                    
                    # Only run if minimization is enabled
                    if self.cfg['pmfuzz']\
                            ['stage']['dedup']['global']['minimize_tc']:
                        prl.run([testcase])
                    else: # else, just create a copy of the destcase
                        copypreserve(testcase, testcase_min_name)

        prl.wait()

    def construct_cmin_sh_files(self, srcdir, scriptsdir, imgdirs, tmp_img):
        """ @brief Constructs the .before.sh and .after.sh for testcases

        @param srcdir Path to directory containing the testcases
        @param scriptsdir Path to directory to write the scripts in
        @param imgdirs List of path to the directory that contains all the 
               compressed img
        @param Path to an empty image for testcases with no parents

        @return None
        """

        # Create config directory containing the command for each testcase
        for f in os.listdir(srcdir):
            tc_name = path.basename(f)
            parent = nh.get_testcase_parent(tc_name)

            # Results of the first stage don't have any parents and have to be 
            # run with empty images
            has_parent = nh.iter_cnt(tc_name) > 1

            with open(path.join(scriptsdir, tc_name + '.before.sh'), 'w') as obj:
                # Generate a decompress commmand to decompress the images only 
                # if the testcase is not from the first stage

                if has_parent:
                    # Src
                    img_src_fname = nh.get_metadata_files(parent)['pm_cmpr_pool']
                    img_src = None

                    for imgdir in imgdirs:
                        img_src = path.join(imgdir, img_src_fname)
                        if os.path.isfile(img_src):
                            break
                    else:
                        abort('No candidate for parent image found in %d dirs'\
                                % len(imgdirs))

                    # Dest
                    img_dest_fname = nh.get_metadata_files(parent)['pm_pool']
                    img_dest = path.join(scriptsdir, img_dest_fname)

                    decompress_cmd = \
                        get_decompress_cmd(img_src, img_dest, self.verbose)

                    # Generate an echo command with the target command
                    tgtcmd_loc = list(self.cfg.tgtcmd)
                    _, tgtcmd_loc \
                        = nh.set_img_path(tgtcmd_loc, img_dest, self.cfg)
                    echo_cmd = 'echo "%s"' % (' '.join(tgtcmd_loc))

                    obj.write(
                        '%s;\n%s;\n' % (' '.join(decompress_cmd), echo_cmd)
                    )
                else:
                    # 1. Set the temp image in tgt command
                    tgtcmd_loc = list(self.cfg.tgtcmd)
                    _, tgtcmd_loc \
                        = nh.set_img_path(tgtcmd_loc, tmp_img, self.cfg)
                    
                    # 2. Generate an echo command with the target command
                    echo_cmd = 'echo "%s"' % (' '.join(tgtcmd_loc))

                    # 3. Construct the shell script and write it
                    obj.write('%s;\n' % (echo_cmd))


            with open(path.join(scriptsdir, tc_name + '.after.sh'), 'w') as obj:
                if has_parent:
                    # Generate command to remove the image
                    rm_img_cmd = 'rm %s' % (img_dest)

                    obj.write('%s;\n' % (rm_img_cmd))
                else:
                    # Don't do anything, ':' character is NOP for shell
                    obj.write(':;\n')

    def minimize_corpus_gbl(self):
        """ @brief Minimizes the global dedup directory.
        
        This method uses modified afl-cmin that supports providing before and 
        after shell scripts that provide the corresponding tgtcmd for each
        testcase. Before and after shell scripts are passed to afl-cmin using
        a config directory (tmp_cfgdir).

        @todo Replace call to copypreserve with a softlink
        @todo Cleanup indir and cfgdir after completion
        @returns None """

        write_state(self.outdir, 'Minimizing global corpus')

        # Create temporary directories for managing corpus
        tmp_indir = tempfile.mkdtemp(prefix='cmin-in-', dir=self.tempdir)
        tmp_mapdir = tempfile.mkdtemp(prefix='cmin-map-dir-', dir=self.tempdir)

        # Copy all the test cases from self.tc_dir to temp directory for corpus
        # minimization
        total_global_count = 0
        for tc, _ in self.global_dedup_list_tc:
            if nh.is_tc(tc):
                total_global_count += 1
                src = tc
                dest = path.join(tmp_indir, path.basename(tc))
                copypreserve(src, dest)

                if self.verbose:
                    printv(f'Copying testcase {src} -> {dest}')

                # Copy the map
                src = path.join(path.dirname(tc), 'map_' + path.basename(tc))
                dest = path.join(tmp_mapdir, 'map_' + path.basename(tc))
                copypreserve(src, dest)
                
                if self.verbose:
                    printv(f'Copying map {src} -> {dest}')

                # Copy the pm map
                src = path.join(path.dirname(tc), 'pm_map_' + path.basename(tc))
                dest = path.join(tmp_mapdir, 'pm_map_' + path.basename(tc))

                if path.isfile(src):
                    copypreserve(src, dest)
                    self.printv(f'Copying map {src} -> {dest}')


        # Create a temp image for cases that don't have any parent
        fd, temp_img = tempfile.mkstemp(prefix='pmfuzz-tmp-img-', 
            dir=self.tempdir)   

        # We don't actually need this file, todo: do better
        os.close(fd)
        os.remove(temp_img)

        _, tgtcmd_loc = \
            nh.set_img_path(list(self.cfg.tgtcmd), temp_img, self.cfg)
        gen_tgt_img(tgtcmd_loc, self.cfg, verbose=self.verbose)

        # Run the actual thing
        outdir = run_afl_cmin(
            indir=tmp_indir, 
            pmfuzzdir=self.outdir, 
            tgtcmd=tgtcmd_loc,
            cfg=self.cfg, 
            # cfgdir=tmp_cfgdir,
            verbose=self.verbose,
            dry_run=False,
            mapdir=tmp_mapdir,
        )

        dropped_files = []
        for f in os.listdir(tmp_indir):
            if f not in os.listdir(outdir):
                dropped_files.append(f)

        if self.verbose:
            printv('Dropping %d of %d testcases after cmin' \
                % (len(dropped_files), total_global_count))
        
        # Remove the dropped testcases and associated metadata files
        for f in dropped_files:
            metadata_files = nh.get_metadata_files(f, deleted=False)
            for metadata_file_type in metadata_files:
                if not metadata_files[metadata_file_type].endswith('.tar.gz'):
                    file_to_delete = path.join(self.dedup_dir_gbl, 
                        metadata_files[metadata_file_type])
                    
                    try:
                        os.remove(file_to_delete)
                        if self.verbose:
                            printv('Removing ' + file_to_delete)
                    except FileNotFoundError:
                        pass

            # Create a placeholder .deleted file to avoid stage1 from 
            # repopulating that testcase
            placeholder_f = path.join(self.dedup_dir_gbl, 
                nh.get_metadata_files(f, deleted=True)['deleted'])

            with open(placeholder_f, 'w') as obj:
                obj.write('deleted at epoch=%d' % int(time.time()))
        
        if self.verbose:
            printv('Removing dir %s' % tmp_indir)
            printv('Removing dir %s' % tmp_mapdir)
            printv('Removing %s' % temp_img)
        
        rmtree(tmp_indir)
        rmtree(tmp_mapdir)
        os.remove(temp_img)
        
        return

    def minimize_corpus_lcl(self):
        """ @brief Minimizes the local testcase directory by combining it with 
        the global testcases.
        
        This method uses modified afl-cmin that supports providing before and 
        after shell scripts that provide the corresponding tgtcmd for each
        testcase. Before and after shell scripts are passed to afl-cmin using
        a config directory (tmp_cfgdir).
        
        @returns None """

        # Create temporary directories for managing corpus
        tmp_indir = tempfile.mkdtemp(prefix='cmin-in-', dir=self.tempdir)
        tmp_mapdir = tempfile.mkdtemp(prefix='cmin-map-dir-', dir=self.tempdir)

        # Copy all testcases from global dedup to tmp_indir to allow 
        # minimization on global corpus along with local
        for f in os.listdir(self.dedup_dir_loc):
            if nh.is_tc(f):
                src = path.join(self.dedup_dir_loc, f)
                dest = path.join(tmp_indir, f)

                if self.verbose:
                    printv(f'Copying to testcase: {src} -> {dest}')

                copypreserve(src, dest)
            elif nh.is_map(f) or nh.is_pm_map(f):
                src = path.join(self.dedup_dir_loc, f)
                dest = path.join(tmp_mapdir, f)

                if path.isfile(src):
                    copypreserve(src, dest)

                    if self.verbose:
                        printv(f'Copying to map: {src} -> {dest}')
                elif self.verbose:
                    printv(f'Did not find {src}')
        
        # Copy all the test cases from self.tc_dir to temp directory for corpus
        # minimization
        lcl_tcs = [path.join(self.tc_dir, f) for f in os.listdir(self.tc_dir)]
        for f in lcl_tcs:
            if nh.is_tc(f):
                src = f
                dest = path.join(tmp_indir, path.basename(f))
                copypreserve(src, dest)

                if self.verbose:
                    printv(f'Copying to testcase: {src} -> {dest}')
            elif nh.is_map(f) or nh.is_pm_map(f):
                src = f
                dest = path.join(tmp_mapdir, path.basename(f))

                if path.isfile(src):
                    copypreserve(src, dest)

                    if self.verbose:
                        printv(f'Copying to map: {src} -> {dest}')
                elif self.verbose:
                    printv(f'Did not find {src}')

        total_tcs = len(os.listdir(tmp_indir))

        # Create a temp image for cases that don't have any parent
        _, temp_img = tempfile.mkstemp(prefix='pmfuzz-tmp-img-', 
                        dir=self.tempdir)
        _, tgtcmd_loc \
            = nh.set_img_path(list(self.cfg.tgtcmd), temp_img, self.cfg)
        gen_tgt_img(tgtcmd_loc, self.cfg, verbose=self.verbose)

        # Run the actual thing
        outdir = run_afl_cmin(
            indir=tmp_indir, 
            pmfuzzdir=self.outdir, 
            tgtcmd=self.cfg.tgtcmd,
            cfg=self.cfg, 
            # cfgdir=tmp_cfgdir,
            verbose=self.verbose,
            mapdir=tmp_mapdir,
            dry_run=False,
        )

        dropped_files = []
        for f in os.listdir(tmp_indir):
            if f not in os.listdir(outdir):
                dropped_files.append(f)

        if self.verbose:
            printv('Dropping %d of %d testcases after cmin' \
                % (len(dropped_files), total_tcs))
        
        # Remove the dropped testcases and associated metadata files from the
        # local testcase directory 
        for f in dropped_files:
            metadata_files = nh.get_metadata_files(f)
            for metadata_file_type in metadata_files:
                file_to_delete = path.join(self.tc_dir, 
                    metadata_files[metadata_file_type])
                
                try:
                    os.remove(file_to_delete)
                    if self.verbose:
                        printv('Removed ' + file_to_delete)
                except FileNotFoundError:
                    pass

        # Remove the dropped testcases and associated metadata files from the
        # global dedup directory 
        for f in dropped_files:
            metadata_files = nh.get_metadata_files(f)
            types_to_delete \
                = ['testcase', 'min_testcase', 'pm_map', 'map']
            for metadata_file_type in types_to_delete:
                file_to_delete = path.join(self.dedup_dir_gbl, 
                    metadata_files[metadata_file_type])
                
                try:
                    os.remove(file_to_delete)
                    placeholder_f = path.join(
                        self.dedup_dir_gbl,   
                        nh.get_metadata_files(f, True)['deleted']
                    )
                    with open(placeholder_f, 'w') as obj:
                        obj.write('Deleted at epoch = ' + str(int(time.time())))
                    if self.verbose:
                        printv('Writing to ' + placeholder_f)
                        printv('Removed ' + file_to_delete)
                except FileNotFoundError:
                    pass

        # TODO: Clean up file descriptors

        if self.verbose:
            printv('Removing dir %s' % tmp_indir)
            printv('Removing dir %s' % tmp_mapdir)
            printv('Removing %s' % temp_img)
        
        rmtree(tmp_indir)
        rmtree(tmp_mapdir)
        os.remove(temp_img)
        
        return

    def deduplicate_crash_sites_lcl(self):
        db = pickledb.load(self.crash_site_db_f, True)

        files = os.listdir(self.img_dir)
        files = [path.join(self.img_dir, fname) for fname in files]

        hash_seen = {}
        files_to_drop = []
        for file_path in filter(nh.is_cmpr_crash_site, files):
            file_name = path.basename(file_path)
            clean_name = file_name.replace('.tar.gz', '')

            hash_v = db.get(clean_name)

            # DB should always carry the hash since it should've been inserted
            # on compressed image generation
            abort_if(hash_v == False, 
                'Unable to find key %s in crash site db (%s)' \
                % (clean_name, hash_v))

            # Add the file to the drop list if the hash is unseen
            if hash_v not in hash_seen:
                hash_seen[hash_v] = True
            else:
                files_to_drop.append(file_name)

        printi('Found %d files to remove' % len(files_to_drop))
        for file_name in files_to_drop:
            file_path = path.join(self.img_dir, file_name)
            if self.verbose:
                hash_val = db.get(file_name.replace('.tar.gz', ''))
                printw('Deleting file %s with hash %s' \
                    % (file_path, hash_val))
            os.remove(file_path)

        if self.verbose:
            orig_count = len(list(filter(nh.is_cmpr_crash_site, files)))
            printv('Original count: ' + str(orig_count))
            printv('hash_seen length: ' + str(len(hash_seen)))
            denominator = orig_count if orig_count > 0 else 1
            printv('Reduced by: ' \
                + str((denominator-len(hash_seen))/denominator*100) + '%')

    def _deduplicate_gbl(self, fdedup, min_tc, min_corpus):
        """ Reads the output of all the stages and deduplicates them """

        printi('Deduplicating global, fdedup: %s, min_tc: %s, min_corpus: %s' % (\
            '1' if fdedup else '0', 
            '1' if min_tc else '0', 
            '1' if min_corpus else '0'))

        if fdedup:
            write_state(self.outdir, 'Deduplicating global testcases')
            if self.verbose:
                printv('Deduplication global testcase')
            testcases_path, _ = map(list, zip(*self.global_dedup_list_tc))
            
            if self.cfg('pmfuzz.dedup.global.fdedup') == 'pm_map':
                DedupEngine(testcases_path, self.verbose, nh.is_pm_map).run()
            elif self.cfg('pmfuzz.dedup.global.fdedup') == 'map':
                DedupEngine(testcases_path, self.verbose, nh.is_map).run()

        if min_tc:
            abort('Minimizing TC doesn\'t make sense')
            if self.verbose:
                printv('Minimizing global testcase')
            write_state(self.outdir, 'Minimizing global testcases')
            self.minimize_testcases()

        if min_corpus:
            if self.verbose:
                printv('Minimizing global corpus')
            write_state(self.outdir, 'Minimizing global corpus')
            self.minimize_corpus_gbl()
            
    def _deduplicate_lcl(self, fdedup, min_tc, min_corpus):
        printi('Deduplicating local')
        
        if fdedup:
            printw('Only deduplicating crash sites, all other deduplications are unimplemented')
            self.deduplicate_crash_sites_lcl()

        if min_tc:
            abort('Unimplemented')
        
        if min_corpus:
            self.minimize_corpus_lcl()

    def run(self, fdedup=True, min_tc=True, min_corpus=True, gbl=True):
        """ @brief Collect and deduplicates all the testcases for the 
        specified stage and iter_id

        @param fdedup Run file based deduplication
        @param min_tc Minimize individual testcases
        @param min_corpus Minimize the global corpus
        
        @return None """
        
        printi('Running dedup for %d.%d' % (self.stage, self.iter_id))

        if gbl:
            self.update_global()
            self._deduplicate_gbl(fdedup, min_tc, min_corpus)
        else:
            self._deduplicate_lcl(fdedup, min_tc, min_corpus)

    @property
    def local_dedup_list(self):
        """ @brief Get all the testcase and corresponding images in the local
        dedup store
        
        @return List of tuple with first entry the path to the testcase and 
                second entry a corresponding path to the image or None """

        result = []

        loc_dedup_files = listdir(self.dedup_dir_loc)

        for filepath in loc_dedup_files:
            
            # Only process testcases
            if nh.is_tc(filepath, all=True):
                entry = [filepath, None]
                
                # If this testcase has a corresponding pool image
                imgpath = filepath.replace(Dedup.EXT_TC, Dedup.EXT_PM_POOL)
                if imgpath in loc_dedup_files:
                    # Add it to the tuple
                    entry[1] = imgpath

                # Add tuple to the results
                result.append(tuple(entry))

        return result

    @property
    def local_dedup_list_st2(self):
        """ @brief Get all the testcase and corresponding images in the local
        dedup store for stage 2 (using filtering)

        This property unlike @ref local_dedup_list() uses config entry 
        (pmfuzz.stage.2.id_selection) to decide if a testcase should be read
        
        @return List of tuple with first entry the path to the testcase and 
                second entry a corresponding path to the image or None """

        result: list = self.local_dedup_list
        
        idx2del = []
        for iter in range(len(result)):
            tc_p, img_p = result[iter]
            if not self.should_use_tc(tc_p):
                idx2del.append(iter)

        if self.verbose:
            printv('Dropping: ' + str(idx2del))

        for idx in sorted(idx2del, reverse=True):
            del result[idx]

        return result
    
    @property
    def global_dedup_list_tc(self):
        """ @brief Get all testcase and corresponding images from global store.

        Does not include crash sites, to list that, see @ref 
        global_dedup_list_cs
        
        @return List of tuple with first entry the path to the testcase and 
                second entry a corresponding path to the image or None """

        result = []

        gbl_dedup_files = listdir(self.dedup_dir_gbl)

        # Complete the path
        gbl_dedup_files = [path.join(self.dedup_dir_gbl, fname) \
                                for fname in gbl_dedup_files]

        for filepath in gbl_dedup_files:
            
            # Only process testcases
            if nh.is_tc(filepath):
                entry = [filepath, None]

                # If this testcase has a corresponding pool image
                imgpath = nh.get_metadata_files(filepath)['pm_cmpr_pool']
                if imgpath in gbl_dedup_files:
                    # Add it to the tuple
                    entry[1] = imgpath
                else:
                    printw('No image found %s' % imgpath)

                # Add tuple to the results
                result.append(tuple(entry))
        
        if self.verbose:
            printv('Returning %d cases' % len(result))

        return result

    @property
    def local_dedup_list_cs(self):
        """ @brief Get all the crash sites in the local image directory.
        
        Does not include local testcases, to list that see @ref 
        local_dedup_list

        @return List of path for every crash site in global dedup store """

        result = []

        local_cs_files = listdir(self.dedup_dir_loc)

        # Complete the path
        local_cs_files = [
            path.join(self.dedup_dir_loc, fname) for fname in local_cs_files
        ]

        for filepath in local_cs_files:
            # Only process testcases
            if nh.is_cmpr_crash_site(filepath):
                result.append(filepath)

        return result

    @property
    def local_dedup_list_cs_st2(self):
        """ @brief Get all the crash sites in the local image directory.
        
        Does not include local testcases, to list that see @ref 
        local_dedup_list

        @return List of path for every crash site in global dedup store """

        result = []

        local_cs_files = listdir(self.dedup_dir_loc)

        # Complete the path
        local_cs_files = [
            path.join(self.dedup_dir_loc, fname) for fname in local_cs_files
        ]

        for filepath in local_cs_files:
            # Only process testcases
            if nh.is_cmpr_crash_site(filepath) \
                    and self.should_use_cs(filepath):
                result.append(filepath)

        if self.verbose:
            printv('Returning cs list: len = ' + str(len(result)))
        return result

    @property
    def global_dedup_list_cs(self):
        """ @brief Get all the crash sites in the global dedup store.
        
        Does not include global testcases, to list that see @ref 
        global_dedup_list_tc

        @return List of path for every crash site in global dedup store """

        result = []

        gbl_dedup_files = listdir(self.dedup_dir_gbl)

        # Complete the path
        gbl_dedup_files = [
            path.join(self.dedup_dir_gbl, fname) for fname in gbl_dedup_files
        ]

        for filepath in gbl_dedup_files:
            # Only process testcases
            if nh.is_cmpr_crash_site(filepath):
                result.append(filepath)

        return result

    @property
    def local_testcases_list(self):
        """ @brief List of all the testcase and corresponding images in the local
        tc/img directories
        
        @return List of tuple with first entry the path to the testcase and 
                second entry a corresponding path to the image or None """

        result = []

        lcl_tc_files = listdir(self.tc_dir)

        # Complete the path
        lcl_tc_files = [path.join(self.tc_dir, fname) for fname in lcl_tc_files\
                            if nh.is_tc(fname)]

        for filepath in lcl_tc_files:
            # If this testcase has a corresponding pool image
            imgname = path.basename(
                        filepath.replace(Dedup.EXT_TC, Dedup.EXT_PM_CMPR_POOL)
            )
            imgpath = path.join(self.img_dir, imgname)

            abort_if(not path.isfile(imgpath), 'Image not found `%s\'' % imgpath)

            # Create a tuple
            entry = (filepath, imgpath)
            
            # Add tuple to the results
            result.append(entry)

        return result

    def update_global(self):
        """ @brief Copies testcases and images from local tc/img store to global 
        store

        Global is updated in two steps:
        1. The testcases and corresponding images are copied
        2. Any crash site generated is copied
        
        @return None """

        printi('Updating global')

        gbl_tc_files = listdir(self.dedup_dir_gbl)

        # 1. Copy testcases and corresponding images
        for testcase, img in self.local_testcases_list:
            dest_name_tc          = path.basename(testcase)
            dest_name_img         = path.basename(img)

            # for deleted cases
            dest_name_placeholder \
                = nh.get_metadata_files(dest_name_tc, deleted=True)['deleted']

            # Copy only if destination does not exists
            if (dest_name_tc not in gbl_tc_files) \
                    and (dest_name_placeholder not in gbl_tc_files):
                printi('Copying files related to ' \
                    + path.basename(dest_name_tc))
                
                # Copy testcase
                src = testcase
                dest = path.join(self.dedup_dir_gbl, dest_name_tc)
                
                copypreserve(src, dest)
                
                if self.verbose:
                    printv('Copying to global dedup: %s -> %s' % (src, dest))
                
                # Copy exec map
                src = testcase
                src = path.join(path.dirname(src), 'map_' + path.basename(src))
                dest = path.join(self.dedup_dir_gbl, 'map_' + dest_name_tc)
                
                if path.isfile(src):
                    copypreserve(src, dest)
                
                    if self.verbose:
                        printv('Copying to exec map: %s -> %s' % (src, dest))
                else:
                    if self.verbose:
                        printv('Unable to find exec map: ' + src)

                # Copy PM map
                src = testcase.replace(Dedup.TESTCASE_DIR, Dedup.TESTCASE_DIR)
                src = path.join(path.dirname(src), 'pm_map_' + path.basename(src))
                dest = path.join(self.dedup_dir_gbl, 'pm_map_' + dest_name_tc)
                
                if path.isfile(src):
                    copypreserve(src, dest)
                
                    if self.verbose:
                        printv('Copying to PM map: %s -> %s' % (src, dest))
                else:
                    if self.verbose:
                        printv('Unable to find PM map: ' + src)

                # Copy image
                src = img
                dest = path.join(self.dedup_dir_gbl, dest_name_img)
                
                copypreserve(src, dest)
                abort_if(not os.path.isfile(dest), 'Cannot copy')
                
                if self.verbose:
                    printv('Copying to global dedup: %s -> %s' % (src, dest))

        # 2. Copy crash sites
        for fname in os.listdir(self.img_dir):
            should_copy = fname not in os.listdir(self.dedup_dir_gbl)

            if nh.is_cmpr_crash_site(fname) and should_copy:
                src = path.join(self.img_dir, fname)
                dest = path.join(self.dedup_dir_gbl, fname)

                if self.verbose:
                    printv('Copying cs %s -> %s' % (src, dest))

                copypreserve(src, dest)

    def update_local(self):
        """ @brief Copies testcases and images from global dedup store to local 
        dedup store 

        Local is updated in two steps:
        1. The testcases and corresponding images are copied
        2. Any crash site generated in the previous interation is copied
        
        @return None """

        printi('Updating local')

        loc_tc_files = listdir(self.dedup_dir_loc)
        loc_tc_files = [f.replace('.min', '') for f in loc_tc_files]

        # 1. Copy testcases
        for testcase, img in self.global_dedup_list_tc:

            # A testcase might not have an associated image
            if img == None:
                img = ''

            dest_name_tc    = path.basename(testcase).replace('.min', '')
            dest_name_img   = path.basename(img)

            #* Note: This piece of code assumes that dedup would only run 
            #* update_local on stage 2
            abort_if(self.stage != 2, 'update_local() is only supported on ' \
                        + 'stage 2')
            is_min_tc   = True #re.search(nh.TC_MIN_REGEX, path.basename(testcase))

            # Make sure this testcase was generated from the immediate parent 
            # of this stage and not earlier than that 
            iter_id     = nh.iter_cnt(path.basename(testcase))
            is_parent   = iter_id == self.iter_id 

            # Copy only if destination does not exists and the testcase is a
            # minimum testcase
            if dest_name_tc not in loc_tc_files and is_min_tc and is_parent:
                src = testcase
                dest = path.join(self.dedup_dir_loc, dest_name_tc)
                
                # Remove 'min' from testestcase name
                dest = dest.replace('.min', '')

                if self.verbose:
                    printv(f'Copying to local dedup: {src} -> {dest}')
                
                copypreserve(src, dest)
                
                if img != '':
                    # Copy image
                    src = img
                    dest = path.join(self.dedup_dir_loc, dest_name_img)

                    # Remove 'min' from testestcase name
                    dest = dest.replace('.min', '')
                    
                    if self.verbose:
                        printv(f'Copying to local dedup: {src} -> {dest}')
                    
                    copypreserve(src, dest)
                    abort_if(not os.path.isfile(dest), 'Cannot copy')

                else:
                    abort('Image not found for %s' % dest_name_tc)

                # Copy map
                testcasebasename = os.path.basename(testcase)
                metadata_files = nh.get_metadata_files(testcasebasename)
                src = os.path.join(self.dedup_dir_gbl, metadata_files['map'])
                dest = os.path.join(self.dedup_dir_loc, metadata_files['map'])
                
                if self.verbose:
                    printv(f'Copying map to local dedup {src} -> {dest}')
                copypreserve(src, dest)

                # Copy PM map
                testcasebasename = os.path.basename(testcase)
                metadata_files = nh.get_metadata_files(testcasebasename)
                src = os.path.join(self.dedup_dir_gbl, metadata_files['pm_map'])
                dest = os.path.join(self.dedup_dir_loc, metadata_files['pm_map'])
                
                copied = False
                if os.path.isfile(src):
                    copied = True
                    copypreserve(src, dest)
                
                if copied:
                    self.printv(f'Copying map to local dedup {src} -> {dest}')
                else:
                    self.printv(f'Did not find {src}')

        if len(self.global_dedup_list_cs) == 0:
            self.printv('Did not find any crash site in global dedup')
        else:
            self.printv('=> ' + str(self.global_dedup_list_cs))

        # 2. Copy crash images
        for cs in self.global_dedup_list_cs:
            if path.basename(cs) not in os.listdir(self.dedup_dir_loc):
                src = cs
                dest = path.join(self.dedup_dir_loc, path.basename(src))

                self.printv('Copying cs: %s -> %s' % (src, dest))

                copypreserve(src, dest)
